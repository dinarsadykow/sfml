{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/skillfactorylogo.png\"></center>\n",
    "\n",
    "<h1><center>Курс \"Практический Machine Learning\"</center></h1>\n",
    "<h3><center>Шестаков Андрей</center></h3>\n",
    "<hr>\n",
    "<h2><center>Логистическая регрессия</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (18,12)\n",
    "\n",
    "from ipywidgets import interact, IntSlider, FloatSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Svm_separating_hyperplanes_%28SVG%29.svg/512px-Svm_separating_hyperplanes_%28SVG%29.svg.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Нам надо найти уравнение прямой (гиперплоскости), которая бы могла разделить два класса ($H_2$ и $H_3$ подходят). В данном случае, уравнение прямой задаётся как: $$g(x) = w_0 + w_1x_1 + w_2x_2 = \\langle w, x \\rangle =  w^\\top x$$\n",
    "\n",
    "* Если $g(x^*) > 0$, то $y^* = +1 = \\text{'черный'}$\n",
    "* Если $g(x^*) < 0$, то $y^* = -1 = \\text{'белый'}$\n",
    "* Если $g(x^*) = 0$, то мы находимся на линии\n",
    "* т.е. решающее правило: $y^* = sign(g(x^*))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def demo_sigmoid():\n",
    "    def sigmoid(z):\n",
    "        return 1./(1. + np.exp(-z))\n",
    "\n",
    "    z = np.linspace(-10, 10, 100)\n",
    "\n",
    "    y = sigmoid(z)\n",
    "    plt.plot(z, y)\n",
    "    plt.xlabel('$z$')\n",
    "    plt.ylabel('$\\sigma(z)$')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Перед тем как мы пойдем дальше, рассмотрим функцию $$\\sigma(z) = \\frac{1}{1 + exp{(-z)}},$$она называется **сигмойда**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "demo_sigmoid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='img/prob.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Постановка задачи\n",
    "Будем требовать, чтобы алгоритм возвращал вероятность класса $y=+1$:\n",
    "$$h(x,w) = p(y=+1|x,w) = \\sigma(g(x))$$\n",
    "\n",
    "Выпишем функцию правдоподобия\n",
    "$$ \\mathcal{L}(w) = \\prod_i^n h(x^{(i)},w)^{[y^{(i)} = +1]} (1 - h(x^{(i)},w))^{[y^{(i)} = -1]} \\rightarrow \\max_w$$\n",
    "$$ -\\log{\\mathcal{L}(w)} = - \\sum_i^n [y^{(i)} = +1]\\cdot\\log{(h(x^{(i)},w))} + {[y^{(i)} = -1]}\\cdot\\log{(1-h(x^{(i)},w))} \\rightarrow \\min_w$$\n",
    "$$L(w) = \\log{\\mathcal{L}(w)} \\rightarrow \\min_w $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X = np.r_[np.random.randn(20, 2) + [2, 2],\n",
    "          np.random.randn(20, 2) + [-2, -2]]\n",
    "y = [-1] * 20 + [1] * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.scatter(X[:, 0],\n",
    "           X[:, 1],\n",
    "           c=y,\n",
    "           cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите логистическую регрессию на этих данных и нарисуйте разделяющую гиперплоскость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=1.0, \n",
    "                           fit_intercept=True, \n",
    "                           penalty='l2')\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'w_0 = %f' % model.intercept_\n",
    "print 'w_1, w_2 = ', model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Нарисуем эту гиперплоскость\n",
    "w_0 = model.intercept_[0]\n",
    "w_1 = model.coef_[0][0]\n",
    "w_2 = model.coef_[0][1]\n",
    "\n",
    "x_1 = np.linspace(-4, 4, 10)\n",
    "x_2 = - (w_0 + w_1*x_1)/w_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.scatter(X[:, 0],\n",
    "           X[:, 1],\n",
    "           c=y,\n",
    "           cmap=plt.cm.Paired)\n",
    "plt.plot(x_1, x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X)\n",
    "y_hat[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_proba = model.predict_proba(X)\n",
    "y_hat_proba[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_func = model.decision_function(X)\n",
    "dec_func[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как сделать нелинейную границу?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим набор данных, который в простонародье называют \"Бублик\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_circles(n_samples=100, shuffle=True,\n",
    "                    noise = 0.1,\n",
    "                    factor=0.1)\n",
    "\n",
    "plt.scatter(X[:, 0],\n",
    "            X[:, 1],\n",
    "            c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что классы нельзя разделить линией. Но можно сделать это окружностью! </br>\n",
    "Т.е. разделяющся линия теперь будет задаваться не уравнением прямой $g(x) = w_0 + w_1x_1 + w_2x_2$, а уравнением окружности $c(x) = (x_1 - a)^2 + (x_2 - b)^2 - R^2$. \n",
    "\n",
    "Выполните преобразование матрицы X, чтобы в ней были столбцы для $x_1$, $x^2_1$, $x_2$, $x^2_2$ и обучите логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.c_[X[:,0], X[:,1], X[:,0]**2, X[:,1]**2]\n",
    "model = LogisticRegression(C=100000, \n",
    "                           fit_intercept=True)\n",
    "model.fit(X_new, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитаем количество ошибок\n",
    "y_hat = model.predict(X_new)\n",
    "(y != y_hat).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нарисуем полученную окружность\n",
    "\n",
    "x0, x1 = np.meshgrid(np.arange(-1.5, 1.5, 0.1),\n",
    "                       np.arange(-1.5, 1.5, 0.1))\n",
    "xx0, xx1 = x0.ravel(), x1.ravel()\n",
    "\n",
    "X_grid = np.c_[xx0, xx1, xx0**2, xx1**2]\n",
    "\n",
    "y_hat = model.decision_function(X_grid)\n",
    "y_hat = y_hat.reshape(x0.shape)\n",
    "\n",
    "plt.contour(x0, x1, y_hat, levels=[0])\n",
    "plt.scatter(X[:,0], \n",
    "            X[:, 1], \n",
    "            c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ тональности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите текстовые данные [отсюда](https://archive.ics.uci.edu/ml/machine-learning-databases/00331/). Архив должен содержать 3 файла с положительными и отрицательными отзывами с ресурсов\n",
    "* imdb.com\n",
    "* amazon.com\n",
    "* yelp.com\n",
    "\n",
    "Формат файла следующий:\n",
    "<отзыв>\\t<метка>\\n\n",
    "\n",
    "\n",
    "### Задача\n",
    "1. Загрузите тексты и метки классов в разные переменные\n",
    "2. Выберите меру качества классификации\n",
    "3. Обучите логистическую (без подбора гиперпараметров). Тексты представляются в виде мешка слов\n",
    "4. Выведите наиболее значимые слова из текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае с логистичесткой регресии, сложность модели выражается в значениях весов $w_j$ при признаках. Больший вес означает большее влияние признака на результат. В таком случае, давайте добавил штрафное слагаемое в функцию оптимизации для логистической регресии. Самый распространенные из них это:\n",
    "\n",
    "Стало (Ridge Regularization)\n",
    "$$ L(\\beta_0,\\beta_1,\\dots) = \\mathcal{L}(w) + \\frac{1}{C}\\sum_{j=1}^{m}w_j^2$$\n",
    "или (Lasso Regularization)\n",
    "$$ L(\\beta_0,\\beta_1,\\dots) = \\mathcal{L}(w)+ \\frac{1}{C}\\sum_{j=1}^{m}|w_j|$$\n",
    "\n",
    "$C$ - называется гиперпараметром регуляризации и он задается вручную. Выбирается он с помощью кросс-валидации. Чем больше $С$ - тем меньше влияние регуляризации.\n",
    "\n",
    "Lasso regression называется так, потому что она осуществляет \"отлов\" признаков - т.е. незначимые признаки будут иметь нулевые веса в модели, в то время как в Ridge regression - веса будут постепенно падать у всех признаков.\n",
    "\n",
    "<img src='http://webdancer.is-programmer.com/user_files/webdancer/Image/lasso.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако использование регуляризации превращает логистическую регрессию в черный ящик - мы предоставляем оптимизационному методу решать за нас, какие признаки важны для модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте сравним работу регуляризаторов. \n",
    "\n",
    "1. Разбейте данные на обучающую и контрольную выборки.\n",
    "1. Для $C$ из набора np.logspace(-3, 3, 10) обучите LogisctigRegression c Lasso регуляризацией (`penalty='l1'`). На каждой итерации оцените качество (ROC-AUC) на контрольной выборке и запомните полученные коэффициенты модели\n",
    "1. На одном графике выведите значение качества в зависимости от параметра `C` \n",
    "1. На другом графике для каждого признака выведите изменение коэффициента в модели в зависимости от параметра `C`\n",
    "1. Для оптимальной на ваш взгляд настройки модели выведите 5 наиболие \"важных\" признаков и их коэффициенты\n",
    "1. Проделайте тоже самое для Ridge регуляризации (`penalty='l2'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_churn = pd.read_csv('data/churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preproc(df_init):\n",
    "    df_preproc = df_init.copy()\n",
    "    \n",
    "    # Удалили признаки\n",
    "    df_preproc = df_preproc.drop(['State', 'Area Code', 'Phone'], axis=1)\n",
    "    \n",
    "    # Замена категориальных признаков\n",
    "    df_preproc.loc[:,  [\"Int'l Plan\", 'VMail Plan']] = \\\n",
    "    df_preproc.loc[:,  [\"Int'l Plan\", 'VMail Plan']].replace({'no': 0, 'yes': 1})\n",
    "    \n",
    "    df_preproc.loc[:,  'Churn?'] = df_preproc.loc[:,  'Churn?'].replace({'False.': 0,\n",
    "                                                                         'True.': 1})\n",
    "    return df_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_preproc = df_churn.pipe(preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = df_preproc.iloc[:, :-1].values, df_preproc.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='l1', C=1, fit_intercept=True)\n",
    "#... После fit()\n",
    "\n",
    "# # Коэффициенты w_1...w_d\n",
    "# model.coef_\n",
    "\n",
    "# # Коэффициент при свободном члене w_0\n",
    "# model.intercept_\n",
    "\n",
    "# # Предсказание\n",
    "# model.predict(X_test)\n",
    "# model.predict_proba(X_test)\n",
    "# model.decision_function(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefs = np.empty((X.shape[1],))\n",
    "scores = []\n",
    "\n",
    "c_range = np.logspace(-3, 3, 10)\n",
    "\n",
    "for C in c_range:\n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', LogisticRegression(penalty='l2', fit_intercept=True, C=C))\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    coefs = np.c_[coefs, model.named_steps['clf'].coef_[0]]\n",
    "    s = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    scores.append(s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(coefs[:, 1:].T)\n",
    "plt.ylabel('weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "291px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
