{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 1. Импорт данных для работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train  (200000, 4)\n",
      "df_test  (170179, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dinar/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df  (370179, 5)\n",
      "df_namedesc  370179\n",
      "CPU times: user 11.1 s, sys: 3.1 s, total: 14.2 s\n",
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import yaml\n",
    "from bs4 import BeautifulSoup # Превращалка html в текст.\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df_sample = pd.read_csv('sampleSubmission.csv', sep = ',')\n",
    "df_train = pd.read_csv('train.csv', sep = '\\t')\n",
    "df_test = pd.read_csv('test.csv', sep = '\\t')\n",
    "print('df_train ',df_train.shape)\n",
    "print('df_test ',df_test.shape)\n",
    "\n",
    "df_train.loc[:, 'sample'] = 'train'\n",
    "df_test.loc[:, 'sample'] = 'test'\n",
    "df = df_test.append(df_train).reset_index(drop=True)\n",
    "print('df ',df.shape)\n",
    "\n",
    "# Переводим текстовы данные из test в словарь 'Название должности' + 'Описание'   \n",
    "df_name = df[['name']].to_dict()['name']\n",
    "df_desc = df[['description']].to_dict()['description']\n",
    "\n",
    "df_namedesc = {}\n",
    "for key in list(df_desc.keys()):\n",
    "    df_namedesc[key] = df_name[key] + ' ' + df_desc[key]\n",
    "print('df_namedesc ',len(df_namedesc))\n",
    "\n",
    "del df_desc\n",
    "del df_name \n",
    "   \n",
    "# del df_sample\n",
    "# del df_train\n",
    "# del df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 2. Подготовка текста: очистка от тегов, оставляем только нужные слова и т.п."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный алгоритм ниже пройден за 4 часа.\n",
    "Результаты записаны в файл 'df_namedesc_re.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# import pymorphy2 # Морфологический анализатор.\n",
    "# from collections import Counter # Не считать же частоты самим.\n",
    "# import math # Корень квадратный.\n",
    "\n",
    "# morph = pymorphy2.MorphAnalyzer() # Создает объект морфоанализатора и загружет словарь.\n",
    "\n",
    "# posConv={'ADJF':'_ADJ','NOUN':'_NOUN','VERB':'_VERB'}\n",
    "# meaningfullPoSes=['ADJF', 'NOUN', 'VERB']\n",
    "# def getArticleDictionary(text, needPos=None):\n",
    "#     words=[a[0] for a in re.findall(\"([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)\", text)]\n",
    "#     reswords=[]\n",
    "#     for w in words:\n",
    "#         wordform=morph.parse(w)[0]\n",
    "#         if wordform.tag.POS in meaningfullPoSes:\n",
    "#             if needPos!=None:\n",
    "#                 reswords.append(wordform.normal_form+posConv[wordform.tag.POS])\n",
    "#             else:\n",
    "#                 reswords.append(wordform.normal_form)\n",
    "#     return Counter(reswords)\n",
    "\n",
    "\n",
    "# df_namedesc_re = {}\n",
    "# for line in df_namedesc.keys():\n",
    "#     df_namedesc_re[line] = ' '.join(list(dict(getArticleDictionary(df_namedesc[line],True).items()).keys()))\n",
    "# print('df_namedesc_re ',len(df_namedesc_re))\n",
    "# del df_namedesc\n",
    "\n",
    "# with open('df_namedesc_re.csv','w') as f:\n",
    "#     for key in list(df_namedesc_re.keys()):\n",
    "#         f.write(str(key) + '\\t' + df_namedesc_re[key] + '\\n')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вытащим эти данные из 'df_namedesc_re.csv' обратно в словарь df_namedesc_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_namedesc_re  370179\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_namedesc_re = {}\n",
    "with open('df_namedesc_re.csv','r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split('\\t')\n",
    "        key = line[0]\n",
    "        value = line[1] if len(line)>1 else ''\n",
    "        df_namedesc_re[key] = value\n",
    "print('df_namedesc_re ',len(df_namedesc_re))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 3. Перевод текста в вектор для машинного обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 289 ms, sys: 203 ms, total: 492 ms\n",
      "Wall time: 671 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from IPython.display import display, Math\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer #импорт декодеров текста в вектор\n",
    "\n",
    "# раскладываем каждый текст на вектор из 'max_features' слов/столбцов\n",
    "coder = CountVectorizer(encoding='utf-8',max_features=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_x_train  (200000, 6000)\n",
      "df_y_train  200000\n",
      "df_x_test  (170179, 6000) \n",
      "\n",
      "CPU times: user 1min 10s, sys: 1min 22s, total: 2min 33s\n",
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_x = coder.fit_transform(df_namedesc_re.values())\n",
    "\n",
    "df_preproc = pd.DataFrame(df_x.toarray())\n",
    "df_preproc['sample'] = df['sample']\n",
    "df_preproc['target'] = df['target']\n",
    "\n",
    "df_train_preproc = df_preproc.query('sample == \"train\"').drop(['sample'], axis=1)\n",
    "df_test_preproc = df_preproc.query('sample == \"test\"').drop(['sample'], axis=1)\n",
    "del df_preproc\n",
    "\n",
    "df_y_train = list(df_train_preproc['target'])\n",
    "df_x_train = df_train_preproc.drop(['target'], axis = 1)\n",
    "df_y_test = list(df_test_preproc['target']) # здесь неизвестные значения Nan - которые нужно найти\n",
    "df_x_test = df_test_preproc.drop(['target'], axis = 1) # здесь входные параметры\n",
    "del df_train_preproc\n",
    "del df_test_preproc\n",
    "\n",
    "print('df_x_train ',df_x_train.shape)\n",
    "print('df_y_train ',len(df_y_train))\n",
    "print('df_x_test ',df_x_test.shape,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dinar/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train, y_train  (134000, 6000) X_test, y  (66000, 6000)\n",
      "CPU times: user 5.99 s, sys: 11.9 s, total: 17.9 s\n",
      "Wall time: 21.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y = train_test_split(df_x_train, df_y_train, test_size=0.33, random_state=42)\n",
    "print('X_train, y_train ',X_train.shape,'X_test, y ',X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 4. Модели машинного обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 71.1 ms, sys: 79.1 ms, total: 150 ms\n",
      "Wall time: 220 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## >>> AVG roc_auc for Train: <<< ########## \n",
      "model3_1. LogisticRegression\t\t\t\t0.9880\n",
      "CPU times: user 6min 29s, sys: 6min 35s, total: 13min 4s\n",
      "Wall time: 16min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model3_1 = LogisticRegression()                     # инициализируем модель\n",
    "model3_1.fit(X_train, y_train)                      # обучаем модель\n",
    "predict = model3_1.predict(X_test)                      # делаем предсказание\n",
    "\n",
    "cross3_1 = cross_val_score(model3_1,df_x_train,df_y_train,scoring='roc_auc', cv=10)\n",
    "print('#'*10,'>>> AVG roc_auc for Train: <<<','#'*10,\n",
    "      '\\nmodel3_1. LogisticRegression\\t\\t\\t\\t{:.4f}'\n",
    "      .format( (sum(cross3_1) / float(len(cross3_1))) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 5. Запись результатов по лучшей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  target\n",
      "0  200000     1.0\n",
      "1  200001     1.0\n",
      "2  200002     1.0\n",
      "3  200003     1.0\n",
      "4  200004     0.0\n",
      "CPU times: user 7.58 s, sys: 18.9 s, total: 26.5 s\n",
      "Wall time: 32.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predict = model3_1.predict(df_x_test)\n",
    "df_predict = pd.DataFrame(list(df_test['id']))\n",
    "df_predict.columns = ['id']\n",
    "df_predict['target'] = pd.DataFrame(predict)\n",
    "print(df_predict.head())\n",
    "\n",
    "df_predict.to_csv('result_submission_hw04_words6000.csv', sep=',', encoding='utf-8',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
